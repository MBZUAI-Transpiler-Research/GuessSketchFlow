{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "model_name = \"celinelee/bartlarge_risctoarm_cloze2048\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "bart_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "\n",
    "bart_tokenizer.padding_side = \"right\"\n",
    "bart_tokenizer.pad_token = bart_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = \"RISC-V\"\n",
    "target_lang = \"ARM64\"\n",
    "source_code = \"\\t.file\\t\\\"cat.c\\\"\\n\\t.option pic\\n\\t.text\\n\\t.align\\t1\\n\\t.globl\\tmain\\n\\t.type\\tmain, @function\\nmain:\\n\\taddi\\tsp,sp,-160\\n\\tsd\\tra,152(sp)\\n\\tsd\\ts0,144(sp)\\n\\taddi\\ts0,sp,160\\n\\tmv\\ta5,a0\\n\\tsd\\ta1,-160(s0)\\n\\tsw\\ta5,-148(s0)\\n\\tla\\ta5,__stack_chk_guard\\n\\tld\\ta4, 0(a5)\\n\\tsd\\ta4, -24(s0)\\n\\tli\\ta4, 0\\n\\tld\\ta5,-160(s0)\\n\\taddi\\ta5,a5,8\\n\\tld\\ta5,0(a5)\\n\\tli\\ta1,0\\n\\tmv\\ta0,a5\\n\\tcall\\topen@plt\\n\\tmv\\ta5,a0\\n\\tsw\\ta5,-136(s0)\\n\\tj\\t.L2\\n.L3:\\n\\tlw\\ta4,-132(s0)\\n\\taddi\\ta5,s0,-128\\n\\tmv\\ta2,a4\\n\\tmv\\ta1,a5\\n\\tli\\ta0,1\\n\\tcall\\twrite@plt\\n.L2:\\n\\taddi\\ta4,s0,-128\\n\\tlw\\ta5,-136(s0)\\n\\tli\\ta2,99\\n\\tmv\\ta1,a4\\n\\tmv\\ta0,a5\\n\\tcall\\tread@plt\\n\\tmv\\ta5,a0\\n\\tsw\\ta5,-132(s0)\\n\\tlw\\ta5,-132(s0)\\n\\tsext.w\\ta5,a5\\n\\tbne\\ta5,zero,.L3\\n\\tli\\ta0,10\\n\\tcall\\tputchar@plt\\n\\tlw\\ta5,-136(s0)\\n\\tmv\\ta0,a5\\n\\tcall\\tclose@plt\\n\\tli\\ta5,0\\n\\tmv\\ta4,a5\\n\\tla\\ta5,__stack_chk_guard\\n\\tld\\ta3, -24(s0)\\n\\tld\\ta5, 0(a5)\\n\\txor\\ta5, a3, a5\\n\\tli\\ta3, 0\\n\\tbeq\\ta5,zero,.L5\\n\\tcall\\t__stack_chk_fail@plt\\n.L5:\\n\\tmv\\ta0,a4\\n\\tld\\tra,152(sp)\\n\\tld\\ts0,144(sp)\\n\\taddi\\tsp,sp,160\\n\\tjr\\tra\\n\\t.size\\tmain, .-main\\n\\t.ident\\t\\\"GCC: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\\\"\\n\\t.section\\t.note.GNU-stack,\\\"\\\",@progbits\\n\"\n",
    "\n",
    "text = f\"Convert the following {source_lang} assembly code to {target_lang} assembly:\\n```{source_lang.lower()}asm\\n{source_code}```\"\n",
    "\n",
    "tokens = bart_tokenizer(\n",
    "    source_code,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"output_attentions\": True,\n",
    "    \"return_dict_in_generate\": True,\n",
    "    \"output_scores\": True,\n",
    "    \"num_beams\": 5,\n",
    "    \"num_return_sequences\": 5\n",
    "}\n",
    "output = bart_model.generate(\n",
    "    **tokens,\n",
    "    max_new_tokens=4096,\n",
    "    temperature=0.7,\n",
    "    do_sample=True,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = bart_tokenizer.batch_decode(\n",
    "    output.sequences,\n",
    "    skip_special_tokens=True,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main:\n",
      "\t.zero\tcfi_startproc\n",
      "\tstp\tx29, x30, [sp, -160]!\n",
      "\t1, -144]!fi_def_cfa_offset 160\n",
      "\tstr\tx2, [x0]\n",
      "\tadd\tx0, sp, 32\n",
      "\tmov\tx1, x8\n",
      "\tldp\tq0, q1, [w1]\n",
      "#APP\n",
      "// 20 \"program193680.c\" 1\n",
      "\tisr\n",
      "// 0 \"\" 2\n",
      "#NO_APP\n",
      "\tbl\topen\n",
      "\tand\tw0, w0, 255\n",
      "\tb\t.L2\n",
      ".L4:\n",
      ".ldrsw\tx3, [xtw\tx4, w3\n",
      "\tsxtwxy\tw\tw1, w1\n",
      "\tlsl\tx5, x1, 5\n",
      "\tlsr\tx6, x5, 4\n",
      "\torr\tx7, x4, x7\n",
      "\tcmp\tw2, 0\n",
      "\tcsel\tx8, x2, x6, ge\n",
      "\tsub\tx20, x3, x0\n",
      "\tnop\n",
      "\tumov\tw3, v0.b[2]\n",
      "\n",
      "\tfmov\td0, 1.0e+0\n",
      ".8\n",
      ".p2align 4,,11\n",
      "\tadrp2, :got:__isoc99_chk_guard\n",
      ".x2fa, lsl #12\n",
      "\tscvtf\ts0, s0.2\n",
      "\tfcmp\ts3, #1.8b}, [x11]\n",
      ".word\t10\n",
      "\tubfx\tx11, x10, 0, 6\n",
      "\tadfm\tPSTL1K, s3, -1.4\n",
      "\tfdiv\tx9, x9, s1\n",
      ".cmn\tsp, #0.cset\tw4, eq\n",
      "\teor\tx10, x11, s5\n",
      "\t{main}.L3K:\n",
      "#intz\tx12, .-main\n",
      "\tbr\tx17\n",
      "\tdsb\tsy\n",
      "\txword\t0, x20\n",
      "\tprfm\tPLDL3K\n",
      "\tmovtzs\tx19, x19\n",
      "\tcsinc\tx18, x18, mi\n",
      "\tudiv\tx16, x17, x16\n",
      "\tmsr, x22, s4\n",
      ".global\t__aarch64_cas4_acq_rel\n",
      ".align\t3\n",
      ".type\ta, %function\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(decoded[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
